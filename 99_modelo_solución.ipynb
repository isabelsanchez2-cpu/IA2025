{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/isabelsanchez2-cpu/IA2025/blob/main/99_modelo_soluci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfJljUSY2Pi9",
        "outputId": "36dafc3b-0476-4bca-af22-2f7b6228c2f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ“ LibrerÃ­as cargadas. Modo CompeticiÃ³n activado.\n",
            "âœ“ Datos cargados. Shape Total: (989286, 19)\n",
            "âœ“ Feature Engineering completado\n",
            "\n",
            "âœ“ Arquitectura Ensemble creada: ['lgbm', 'xgb']\n",
            "\n",
            "========================================\n",
            "VALIDACIÃ“N CRUZADA (5-FOLDS)\n",
            "========================================\n",
            "\n",
            "ðŸ† CV ACCURACY SCORE: 0.44095\n",
            "âš  Ajusta learning_rate o features.\n",
            "\n",
            "Entrenando modelo final en todo el dataset...\n",
            "âœ“ Modelo entrenado.\n",
            "Generando predicciones test...\n",
            "\n",
            "DistribuciÃ³n de Predicciones:\n",
            "  alto: 83657 (28.19%)\n",
            "  bajo: 91361 (30.78%)\n",
            "  medio-alto: 61522 (20.73%)\n",
            "  medio-bajo: 60246 (20.30%)\n",
            "\n",
            "============================================================\n",
            "âœ“ ARCHIVO GENERADO: submission_ensemble_cv0.44095.csv\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# 100 - MODELO CHAMPION: ENSEMBLE LGBM + XGB (META: > 0.44870)\n",
        "# ============================================================================\n",
        "\n",
        "# %% [markdown]\n",
        "\"\"\"\n",
        "# 100 - Modelo Champion: Velocidad y PrecisiÃ³n\n",
        "\n",
        "## Estrategia para batir 0.44869:\n",
        "1. **Velocidad:** Uso de tipos de datos 'category' nativos (evita loops lentos).\n",
        "2. **Features:** Agregaciones estadÃ­sticas vectorizadas + Conteos de nulos.\n",
        "3. **Arquitectura:** VotingClassifier (Soft Voting) entre LightGBM y XGBoost.\n",
        "   - LightGBM: Optimizado para 'leaf-wise' (profundidad asimÃ©trica).\n",
        "   - XGBoost: Optimizado para regularizaciÃ³n (evita overfitting).\n",
        "\"\"\"\n",
        "\n",
        "# %% 1. Importaciones Optimizadas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "import warnings\n",
        "import gc\n",
        "\n",
        "# Intentar importar los motores potentes\n",
        "try:\n",
        "    from lightgbm import LGBMClassifier\n",
        "    LGBM_AVAILABLE = True\n",
        "except ImportError:\n",
        "    LGBM_AVAILABLE = False\n",
        "    print(\"âš  ADVERTENCIA: LightGBM no instalado. Instala con: pip install lightgbm\")\n",
        "\n",
        "try:\n",
        "    from xgboost import XGBClassifier\n",
        "    XGB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    XGB_AVAILABLE = False\n",
        "    print(\"âš  ADVERTENCIA: XGBoost no instalado. Instala con: pip install xgboost\")\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "print('âœ“ LibrerÃ­as cargadas. Modo CompeticiÃ³n activado.')\n",
        "\n",
        "# %% 2. Carga y Preprocesamiento RÃ¡pido\n",
        "# ERROR: FileNotFoundError. AsegÃºrate de que 'train.csv' y 'test.csv' estÃ©n en el entorno de Colab\n",
        "# (por ejemplo, subiÃ©ndolos o montando Google Drive).\n",
        "train = pd.read_csv('train (1).csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "# Guardar IDs y Target\n",
        "train_ids = train['ID']\n",
        "test_ids = test['ID']\n",
        "y_raw = train['RENDIMIENTO_GLOBAL']\n",
        "\n",
        "# Mapeo del target (Esencial para XGBoost/LGBM)\n",
        "target_map = {'bajo': 0, 'medio-bajo': 1, 'medio-alto': 2, 'alto': 3}\n",
        "inv_target_map = {v: k for k, v in target_map.items()}\n",
        "y = y_raw.map(target_map)\n",
        "\n",
        "# Unir para procesar categÃ³ricas juntas (ahorra cÃ³digo y errores)\n",
        "df_all = pd.concat([train.drop(['ID', 'RENDIMIENTO_GLOBAL'], axis=1),\n",
        "                    test.drop(['ID'], axis=1)], axis=0).reset_index(drop=True)\n",
        "\n",
        "print(f'âœ“ Datos cargados. Shape Total: {df_all.shape}')\n",
        "\n",
        "# %% 3. Feature Engineering Vectorizado (Velocidad Pura)\n",
        "\n",
        "# Identificar columnas\n",
        "num_cols = df_all.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "cat_cols = df_all.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "# A. EstadÃ­sticas de Indicadores (Si existen columnas que empiezan con INDICADOR)\n",
        "ind_cols = [c for c in num_cols if 'INDICADOR' in c]\n",
        "if ind_cols:\n",
        "    # EstadÃ­sticas bÃ¡sicas\n",
        "    df_all['IND_MEAN'] = df_all[ind_cols].mean(axis=1)\n",
        "    df_all['IND_STD'] = df_all[ind_cols].std(axis=1)\n",
        "    df_all['IND_MAX'] = df_all[ind_cols].max(axis=1)\n",
        "    df_all['IND_MIN'] = df_all[ind_cols].min(axis=1)\n",
        "    df_all['IND_RANGE'] = df_all['IND_MAX'] - df_all['IND_MIN']\n",
        "\n",
        "    # Feature importante: Suma de valores (proxy de intensidad)\n",
        "    df_all['IND_SUM'] = df_all[ind_cols].sum(axis=1)\n",
        "\n",
        "# B. Conteo de Nulos (Muy informativo en educaciÃ³n/encuestas)\n",
        "df_all['NULL_COUNT'] = df_all.isnull().sum(axis=1)\n",
        "\n",
        "# C. Limpieza y CodificaciÃ³n RÃ¡pida\n",
        "# NumÃ©ricas: Rellenar con media\n",
        "for col in num_cols:\n",
        "    df_all[col] = df_all[col].fillna(df_all[col].median())\n",
        "\n",
        "# CategÃ³ricas: Label Encoding (Necesario para LGBM/XGB si no usamos OneHot)\n",
        "# LightGBM funciona mejor con nÃºmeros enteros que representan categorÃ­as\n",
        "lbl = LabelEncoder()\n",
        "for col in cat_cols:\n",
        "    df_all[col] = df_all[col].astype(str).fillna('MISSING')\n",
        "    df_all[col] = lbl.fit_transform(df_all[col])\n",
        "    # Convertir explÃ­citamente a category para LightGBM\n",
        "    df_all[col] = df_all[col].astype('category')\n",
        "\n",
        "print('âœ“ Feature Engineering completado')\n",
        "\n",
        "# %% 4. Separar Datasets\n",
        "X = df_all.iloc[:len(train)].copy()\n",
        "X_test = df_all.iloc[len(train):].copy()\n",
        "\n",
        "# Limpiar memoria\n",
        "del df_all, train, test\n",
        "gc.collect()\n",
        "\n",
        "# %% 5. ConfiguraciÃ³n de Modelos \"Champion\"\n",
        "\n",
        "# Definir los modelos base con hiperparÃ¡metros ajustados para generalizaciÃ³n\n",
        "estimators = []\n",
        "\n",
        "if LGBM_AVAILABLE:\n",
        "    # LightGBM: RÃ¡pido y preciso con categorÃ­as\n",
        "    lgbm_clf = LGBMClassifier(\n",
        "        n_estimators=1200,\n",
        "        learning_rate=0.02,       # Bajo para mejor convergencia\n",
        "        num_leaves=31,            # EstÃ¡ndar robusto\n",
        "        max_depth=-1,             # Sin lÃ­mite estricto, controlado por num_leaves\n",
        "        min_child_samples=20,\n",
        "        subsample=0.8,            # Evita overfitting\n",
        "        colsample_bytree=0.7,     # Evita overfitting\n",
        "        reg_alpha=0.1,            # RegularizaciÃ³n L1\n",
        "        reg_lambda=0.1,           # RegularizaciÃ³n L2\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        verbose=-1,\n",
        "        class_weight='balanced'   # Crucial si hay desbalance\n",
        "    )\n",
        "    estimators.append(('lgbm', lgbm_clf))\n",
        "\n",
        "if XGB_AVAILABLE:\n",
        "    # XGBoost: Profundo y robusto\n",
        "    xgb_clf = XGBClassifier(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.02,\n",
        "        max_depth=6,              # Profundidad media\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.7,\n",
        "        gamma=0.1,                # RegularizaciÃ³n mÃ­nima de split\n",
        "        reg_alpha=0.05,\n",
        "        reg_lambda=0.05,\n",
        "        enable_categorical=True,  # Activar soporte nativo (muy rÃ¡pido)\n",
        "        random_state=42,\n",
        "        n_jobs=-1,\n",
        "        eval_metric='mlogloss'\n",
        "        # Nota: XGBoost maneja 'balanced' internamente diferente, lo dejamos default o ajustamos scale_pos_pos_weight manualmente\n",
        "    )\n",
        "    estimators.append(('xgb', xgb_clf))\n",
        "\n",
        "# Crear el Ensemble (VotaciÃ³n Suave)\n",
        "# Soft Voting promedia las probabilidades, suavizando errores individuales\n",
        "model = VotingClassifier(\n",
        "    estimators=estimators,\n",
        "    voting='soft',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(f'\\nâœ“ Arquitectura Ensemble creada: {[n for n, _ in estimators]}')\n",
        "\n",
        "# %% 6. ValidaciÃ³n Cruzada y Entrenamiento\n",
        "\n",
        "print('\\n' + '='*40)\n",
        "print('VALIDACIÃ“N CRUZADA (5-FOLDS)')\n",
        "print('='*40)\n",
        "\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Cross_val_predict es eficiente para obtener predicciones OOF (Out Of Fold)\n",
        "# y estimar el score real sin loops manuales complejos\n",
        "oof_preds = cross_val_predict(model, X, y, cv=skf, n_jobs=-1, method='predict')\n",
        "\n",
        "cv_score = accuracy_score(y, oof_preds)\n",
        "print(f'\\nðŸ† CV ACCURACY SCORE: {cv_score:.5f}')\n",
        "\n",
        "if cv_score > 0.44869:\n",
        "    print('ðŸš€ Â¡POTENCIAL DE NUEVO RECORD DETECTADO!')\n",
        "elif cv_score > 0.44800:\n",
        "    print('âœ… Muy competitivo. Posible top leaderboard.')\n",
        "else:\n",
        "    print('âš  Ajusta learning_rate o features.')\n",
        "\n",
        "# %% 7. Entrenamiento Final y PredicciÃ³n\n",
        "\n",
        "print('\\nEntrenando modelo final en todo el dataset...')\n",
        "model.fit(X, y)\n",
        "print('âœ“ Modelo entrenado.')\n",
        "\n",
        "print('Generando predicciones test...')\n",
        "test_probs = model.predict_proba(X_test)\n",
        "test_preds = np.argmax(test_probs, axis=1)\n",
        "\n",
        "# Mapeo inverso a strings\n",
        "final_predictions = [inv_target_map[p] for p in test_preds]\n",
        "\n",
        "# DistribuciÃ³n\n",
        "print('\\nDistribuciÃ³n de Predicciones:')\n",
        "unique, counts = np.unique(final_predictions, return_counts=True)\n",
        "for u, c in zip(unique, counts):\n",
        "    print(f'  {u}: {c} ({c/len(final_predictions)*100:.2f}%)')\n",
        "\n",
        "# %% 8. Generar Submission\n",
        "submission = pd.DataFrame({\n",
        "    'ID': test_ids,\n",
        "    'RENDIMIENTO_GLOBAL': final_predictions\n",
        "})\n",
        "\n",
        "filename = f'submission_ensemble_cv{cv_score:.5f}.csv'\n",
        "submission.to_csv(filename, index=False)\n",
        "\n",
        "print('\\n' + '='*60)\n",
        "print(f'âœ“ ARCHIVO GENERADO: {filename}')\n",
        "print('='*60)"
      ]
    }
  ]
}